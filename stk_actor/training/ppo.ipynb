{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from pystk2_gymnasium import AgentSpec\n",
    "from pystk2_gymnasium.envs import STKRaceEnv\n",
    "from pystk2_gymnasium.stk_wrappers import ConstantSizedObservations, DiscreteActionsWrapper\n",
    "from pystk2_gymnasium.wrappers import FlattenerWrapper, SpaceFlattener\n",
    "from pystk2_gymnasium.definitions import ActionObservationWrapper\n",
    "from test_ai import ActionOnlyFlattenerWrapper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from pystk2_gymnasium import AgentSpec\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean = torch.tensor([0.71151, 0.0, -0.061457, -0.10169, 3.4319, -0.52413, 661.15, 0.42724, 2.7327e-05, 3.1487e-05, 0.71825, -0.018171, -0.021021, 43.886, -0.0085404, -0.0041873, 51.719, -0.0010554, -0.0016169, 62.018, -0.006209, -0.00017353, 84.65, -0.0022044, -0.05316, 94.29, -0.000844, 0.014244, 31.789, -0.051845, 0.05947, 50.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091044, 657.46, 665.37, 660.0, 667.5, 661.4, 668.77, 662.42, 669.61, 663.63, 670.71, 0.026151, 0.041322, 7.6908, 0.012883, 0.0072263, 14.788, 0.0044946, -0.0027369, 21.985, -0.0037865, -0.0051671, 28.917, -0.010331, -0.0035413, 35.536, 0.07285, 0.069774, 6.6553, 0.023434, 0.04203, 8.1486, 0.011373, 0.0085714, 15.25, 0.0030726, -0.0013871, 22.422, -0.0040406, -0.0039074, 29.326, 10.412, 10.378, 10.354, 10.331, 10.314, 0.048839, 1.0454, -0.005195, 0.018967, 21.373])\n",
    "state_std  = torch.tensor([3.5549, 1.0, 1.6011, 1.7763, 10.69, 11.215, 512.81, 0.70422, 0.021198, 0.027364, 0.07953, 0.73691, 0.40548, 35.889, 0.75692, 0.4407, 36.7, 0.83793, 0.53804, 43.32, 1.0244, 0.72855, 48.63, 1.1039, 0.83519, 48.809, 1.572, 1.6809, 26.944, 2.1913, 2.4827, 36.348, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.084412, 512.98, 512.19, 511.66, 510.81, 509.95, 509.12, 508.47, 507.75, 507.13, 506.41, 0.7026, 0.58222, 14.014, 0.46184, 0.46873, 17.612, 0.43538, 0.4327, 21.155, 0.45335, 0.42052, 24.391, 0.49166, 0.42006, 27.216, 2.4385, 2.7218, 14.038, 0.70692, 0.58753, 17.399, 0.46856, 0.47626, 20.34, 0.44233, 0.44088, 23.3, 0.46, 0.42836, 26.018, 2.8646, 2.853, 2.8597, 2.8823, 2.9084, 0.58635, 0.22906, 1.3934, 1.5918, 7.0388])\n",
    "\n",
    "def state_to_tensor(state):\n",
    "\n",
    "    continuous_vars = ['attachment_time_left', 'center_path', 'center_path_distance', 'distance_down_track', 'energy', 'front', 'items_position', 'karts_position', 'max_steer_angle', 'paths_distance', 'paths_end', 'paths_start', 'paths_width', 'shield_time', 'skeed_factor', 'velocity']\n",
    "\n",
    "    continuous_state = []\n",
    "    for key in continuous_vars:\n",
    "        value = state[key]\n",
    "        num_envs = value.shape[0]\n",
    "        if key in ['items_position', 'paths_end', 'paths_start', 'paths_width']:\n",
    "            normalized_value = value[..., :5, :]\n",
    "        else:    \n",
    "            # normalized_value = (value - self.means[key]) / self.stds[key]\n",
    "            normalized_value = value\n",
    "            \n",
    "        continuous_state.append(normalized_value.reshape(num_envs, -1))\n",
    "\n",
    "    continuous_state = np.concatenate(continuous_state, axis=-1)\n",
    "    state = torch.tensor(continuous_state)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithMultipleHeads(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dims):\n",
    "        super(MLPWithMultipleHeads, self).__init__()\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.heads = nn.ModuleList([\n",
    "            # nn.Linear(hidden_dim, out_dim)\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, out_dim),\n",
    "            )\n",
    "            for out_dim in output_dims])\n",
    "        \n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, action=None):\n",
    "        shared_output = self.shared_layers(x)\n",
    "        action_logits = [head(shared_output) for head in self.heads]\n",
    "        \n",
    "\n",
    "        dists = [Categorical(logits=action_logits[i]) for i in range(len(action_logits))]\n",
    "\n",
    "        if action is None:\n",
    "            action = torch.stack([dist.sample() for dist in dists], dim=-1)\n",
    "        \n",
    "        log_ps = [F.log_softmax(action_logits[i], dim=-1).gather(-1, action[:, i].unsqueeze(-1)).squeeze(-1) for i in range(len(self.heads))]\n",
    "        log_p = torch.stack(log_ps, dim=-1).sum(dim=-1)\n",
    "        \n",
    "        value = self.critic(x)\n",
    "        \n",
    "        entropy = sum([dist.entropy().mean() for dist in dists])\n",
    "        \n",
    "        return action, log_p, value, entropy\n",
    "\n",
    "\n",
    "# model = MLPWithMultipleHeads(134, 256, [5, 2, 2, 2, 2, 2, 7])\n",
    "\n",
    "# x = torch.rand((777, 134))\n",
    "# action, log_p, value, entropy = model(x)\n",
    "# new_action, new_log_p, new_value, _ = model(x, action=action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae_parallel(dones, rewards, values, next_values, gamma=0.99, lambda_=0.95):\n",
    "    assert (\n",
    "        dones.shape == rewards.shape == values.shape == next_values.shape\n",
    "    ), \"All inputs must have the same shape (num_envs, sequence_length).\"\n",
    "\n",
    "    num_envs, seq_len = dones.shape\n",
    "    advantages = torch.zeros_like(rewards, dtype=torch.float32)\n",
    "    returns = torch.zeros_like(rewards, dtype=torch.float32)\n",
    "    last_advantage = torch.zeros(num_envs, dtype=torch.float32)\n",
    "    last_return = torch.zeros(num_envs, dtype=torch.float32)\n",
    "\n",
    "    for t in reversed(range(seq_len)):\n",
    "        mask = 1.0 - dones[:, t]\n",
    "        last_value = next_values[:, t] * mask\n",
    "        last_advantage = last_advantage * mask\n",
    "        last_return = last_return * mask\n",
    "\n",
    "        delta = rewards[:, t] + gamma * last_value - values[:, t]\n",
    "        last_advantage = delta + gamma * lambda_ * last_advantage\n",
    "        last_return = rewards[:, t] + gamma * last_return\n",
    "\n",
    "        advantages[:, t] = last_advantage\n",
    "        returns[:, t] = last_return\n",
    "\n",
    "    return advantages, returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(env, state, model, n_steps):\n",
    "\n",
    "    states, actions, rewards, log_ps, state_values, dones = [], [], [], [], [], []\n",
    "\n",
    "    # state, _ = env.reset()\n",
    "    \n",
    "\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        state = state_to_tensor(state)\n",
    "        action, log_p, state_value, entropy = model(state)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated | truncated\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        log_ps.append(log_p)\n",
    "        state_values.append(state_value)\n",
    "        dones.append(done * 1.)\n",
    "\n",
    "        \n",
    "        # if any(done):\n",
    "        #     # print(done)\n",
    "        #     # Manually reset done environments if needed\n",
    "        #     for i in range(len(done)):\n",
    "        #         if done[i]:\n",
    "        #             new_state, _ = env.envs[i].reset()\n",
    "        #             next_state[i] = new_state\n",
    "                    \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "                    \n",
    "    \n",
    "    next_state = state_to_tensor(next_state)\n",
    "    # print(next_state.shape)\n",
    "    next_value = model.critic(next_state).squeeze(-1)\n",
    "    \n",
    "    states = torch.stack(states)\n",
    "    actions = torch.stack(actions)\n",
    "    rewards = torch.tensor(rewards)\n",
    "    state_values = torch.stack(state_values).squeeze(-1)\n",
    "    dones = torch.tensor(dones)\n",
    "\n",
    "    next_state_values = torch.concatenate((state_values[1:], next_value.unsqueeze(0)), dim=0)\n",
    "    \n",
    "    # advantages, returns = compute_gae(dones, rewards, state_values, next_state_values)\n",
    "    advantages, returns = compute_gae_parallel(dones, rewards, state_values, next_state_values)\n",
    "         \n",
    "    # Normalize advantages\n",
    "    # advantages = torch.FloatTensor(advantages)\n",
    "    returns = advantages + state_values\n",
    "            \n",
    "    trajectories = {\n",
    "        \"states\" : states.reshape(-1, 121).detach(),\n",
    "        \"actions\" : actions.reshape(-1, 7).detach(),\n",
    "        \"rewards\" : rewards.reshape(-1).detach(),\n",
    "        \"dones\" : dones.reshape(-1).detach(),\n",
    "        \"log_ps\" : torch.stack(log_ps).reshape(-1).detach(),\n",
    "        \"state_values\": state_values.reshape(-1).detach(),\n",
    "        \"next_state_values\": next_state_values.reshape(-1).detach(),\n",
    "        \"returns\" : returns.reshape(-1).detach(),\n",
    "        \"advantages\" : advantages.reshape(-1).detach(),\n",
    "    }\n",
    "    \n",
    "    return trajectories, state\n",
    "\n",
    "\n",
    "# trajectories = collect_trajectories(env, model, n_steps=128)\n",
    "\n",
    "# for key in trajectories:\n",
    "#     print(key, trajectories[key].shape)\n",
    "\n",
    "def shufffle_trajectory(trajectories):\n",
    "    length = trajectories['states'].shape[0]\n",
    "    permutation = torch.randperm(length)\n",
    "\n",
    "    shuffled_trajectories = {key: tensor[permutation] for key, tensor in trajectories.items()}\n",
    "    return shuffled_trajectories\n",
    "\n",
    "# shuffled_trajectories = shufffle_trajectory(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_envs = 8\n",
    "# env = gym.vector.SyncVectorEnv([\n",
    "#     lambda: gym.make(\"supertuxkart/flattened_multidiscrete-v0\", render_mode=None, agent=AgentSpec(use_ai=True))\n",
    "#     for _ in range(num_envs)\n",
    "# ])                                  \n",
    "\n",
    "# state, _ = env.reset()                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_optimization(trajectories, model, optimizer, epochs, batch_size):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    traj_states = trajectories[\"states\"]\n",
    "    traj_actions = trajectories[\"actions\"]\n",
    "    traj_log_ps = trajectories[\"log_ps\"]\n",
    "    traj_returns = trajectories[\"returns\"]  \n",
    "    traj_advantages = trajectories[\"advantages\"]\n",
    "\n",
    "\n",
    "    len_trajectory = traj_states.shape[0]\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for i in range(len_trajectory // batch_size):\n",
    "            state = traj_states[batch_size*i:batch_size*(i+1)]\n",
    "            action = traj_actions[batch_size*i:batch_size*(i+1)]\n",
    "            log_p = traj_log_ps[batch_size*i:batch_size*(i+1)]\n",
    "            return_ = traj_returns[batch_size*i:batch_size*(i+1)]\n",
    "            advantage = traj_advantages[batch_size*i:batch_size*(i+1)]\n",
    "            \n",
    "            new_action, new_log_p, new_state_value, entropy = model(state, action)\n",
    "            assert(new_action == action).all()\n",
    "            \n",
    "            \n",
    "            advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "                    \n",
    "            new_log_p, log_p, advantage = new_log_p.reshape(-1), log_p.reshape(-1), advantage.reshape(-1)\n",
    "            \n",
    "            \n",
    "            ratio = torch.exp(new_log_p - log_p.detach())\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1-0.2, 1+0.2) * advantage\n",
    "            policy_loss = - torch.min(surr1, surr2).mean()\n",
    "            \n",
    "            \n",
    "            return_, new_state_value = return_.reshape(-1), new_state_value.reshape(-1)\n",
    "\n",
    "            value_loss = ((return_ - new_state_value)**2).mean()\n",
    "\n",
    "            loss = policy_loss - 1e-5*entropy.mean() + 0.5*value_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_factor = torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            \n",
    "# ppo_optimization(trajectories, model, optimizer, epochs=1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionOnlyFlattenerWrapper(ActionObservationWrapper):\n",
    "    \"\"\"Flattens actions and observations.\"\"\"\n",
    "\n",
    "    def __init__(self, env: gym.Env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.action_flattener = SpaceFlattener(env.action_space)\n",
    "        self.action_space = self.action_flattener.space\n",
    "        \n",
    "    def observation(self, observation):\n",
    "        return observation\n",
    "\n",
    "\n",
    "    def action(self, action):\n",
    "        discrete_actions = {}\n",
    "        if not self.action_flattener.only_continuous:\n",
    "            actions = (\n",
    "                action if self.action_flattener.only_discrete else action[\"discrete\"]\n",
    "            )\n",
    "            assert len(self.action_flattener.discrete_keys) == len(actions), (\n",
    "                \"Not enough discrete values: \"\n",
    "                f\"\"\"expected {len(self.action_flattener.discrete_keys)}, \"\"\"\n",
    "                f\"\"\"got {len(action)}\"\"\"\n",
    "            )\n",
    "            discrete_actions = {\n",
    "                key: key_action\n",
    "                for key, key_action in zip(self.action_flattener.discrete_keys, actions)\n",
    "            }\n",
    "\n",
    "        continuous_actions = {}\n",
    "        if not self.action_flattener.only_discrete:\n",
    "            actions = (\n",
    "                action\n",
    "                if self.action_flattener.only_continuous\n",
    "                else action[\"continuous\"]\n",
    "            )\n",
    "            continuous_actions = {\n",
    "                key: actions[\n",
    "                    self.action_flattener.indices[ix] : self.action_flattener.indices[\n",
    "                        ix + 1\n",
    "                    ]\n",
    "                ].reshape(shape)\n",
    "                for ix, (key, shape) in enumerate(\n",
    "                    zip(\n",
    "                        self.action_flattener.continuous_keys,\n",
    "                        self.action_flattener.shapes,\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "\n",
    "        return {**discrete_actions, **continuous_actions}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = STKRaceEnv(agent=AgentSpec(use_ai=False), render_mode=None)\n",
    "# env = gym.wrappers.PassiveEnvChecker(env)\n",
    "# env = gym.wrappers.OrderEnforcing(env)\n",
    "# env = gym.wrappers.TimeLimit(env, max_episode_steps=1500)\n",
    "# env = ConstantSizedObservations(env, state_paths=20, state_items=20)\n",
    "# env = DiscreteActionsWrapper(env)\n",
    "# env = ActionOnlyFlattenerWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    }
   ],
   "source": [
    "num_envs = 1\n",
    "\n",
    "def make_env():\n",
    "    env = STKRaceEnv(agent=AgentSpec(use_ai=False), render_mode=\"human\")\n",
    "    env = gym.wrappers.PassiveEnvChecker(env)\n",
    "    env = gym.wrappers.OrderEnforcing(env)\n",
    "    env = gym.wrappers.TimeLimit(env, max_episode_steps=1500)\n",
    "    env = ConstantSizedObservations(env, state_paths=20, state_items=20)\n",
    "    env = DiscreteActionsWrapper(env)\n",
    "    env = ActionOnlyFlattenerWrapper(env)\n",
    "    return env\n",
    "\n",
    "env = gym.vector.SyncVectorEnv([\n",
    "    lambda: make_env()\n",
    "    for _ in range(num_envs)\n",
    "])\n",
    "\n",
    "init_state, _ = env.reset()\n",
    "last_state = init_state\n",
    "\n",
    "\n",
    "from types import MethodType\n",
    "\n",
    "def modified_get_state(self, kart_ix: int, use_ai: bool):\n",
    "        kart = self.world.karts[kart_ix]\n",
    "        terminated = kart.has_finished_race\n",
    "\n",
    "        # Get the observation and update the world state\n",
    "        obs = self.get_observation(kart_ix, use_ai)\n",
    "\n",
    "        d_t = max(0, kart.overall_distance)\n",
    "        f_t = 1 if terminated else 0\n",
    "        reward = (\n",
    "            (d_t - self.last_overall_distances[kart_ix]) / 10.0\n",
    "            # + (1.0 - kart.position / self.num_kart) * (3 + 7 * f_t)\n",
    "            # - 0.1\n",
    "            # + 10 * f_t\n",
    "        )\n",
    "        return (\n",
    "            obs,\n",
    "            reward,\n",
    "            terminated,\n",
    "            {\n",
    "                \"position\": kart.position,\n",
    "                \"distance\": d_t,\n",
    "            },\n",
    "        )\n",
    "\n",
    "for i in range(len(env.envs)):\n",
    "    env.envs[i].unwrapped.get_state = MethodType(modified_get_state, env.envs[0].unwrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13285/235525333.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/behavioral_cloning.pt'))\n"
     ]
    }
   ],
   "source": [
    "model = MLPWithMultipleHeads(\n",
    "    input_dim=121,\n",
    "    hidden_dim=512,\n",
    "    output_dims=[5, 2, 2, 2, 2, 2, 7]\n",
    ")\n",
    "model.load_state_dict(torch.load('models/behavioral_cloning.pt'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 320/1000 [00:04<00:09, 68.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     trajectories, last_state \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     shuffled_trajectory \u001b[38;5;241m=\u001b[39m shufffle_trajectory(trajectories)\n\u001b[1;32m      5\u001b[0m     ppo_optimization(shuffled_trajectory, model, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "Cell \u001b[0;32mIn[150], line 14\u001b[0m, in \u001b[0;36mcollect_trajectories\u001b[0;34m(env, state, model, n_steps)\u001b[0m\n\u001b[1;32m     12\u001b[0m state \u001b[38;5;241m=\u001b[39m state_to_tensor(state)\n\u001b[1;32m     13\u001b[0m action, log_p, state_value, entropy \u001b[38;5;241m=\u001b[39m model(state)\n\u001b[0;32m---> 14\u001b[0m next_state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;241m|\u001b[39m truncated\n\u001b[1;32m     17\u001b[0m states\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/gymnasium/vector/sync_vector_env.py:221\u001b[0m, in \u001b[0;36mSyncVectorEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncations[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     (\n\u001b[1;32m    216\u001b[0m         env_obs,\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rewards[i],\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terminations[i],\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncations[i],\n\u001b[1;32m    220\u001b[0m         env_info,\n\u001b[0;32m--> 221\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m observations\u001b[38;5;241m.\u001b[39mappend(env_obs)\n\u001b[1;32m    224\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_info(infos, env_info, i)\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/definitions.py:63\u001b[0m, in \u001b[0;36mActionObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m:meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction(action)\n\u001b[0;32m---> 63\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/definitions.py:63\u001b[0m, in \u001b[0;36mActionObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m:meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction(action)\n\u001b[0;32m---> 63\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/gymnasium/core.py:550\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/gymnasium/wrappers/common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/envs.py:479\u001b[0m, in \u001b[0;36mSTKRaceEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrace_step(get_action(action))\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_update()\n\u001b[0;32m--> 479\u001b[0m obs, reward, terminated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkart_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_ai\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (obs, reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, info)\n",
      "Cell \u001b[0;32mIn[147], line 29\u001b[0m, in \u001b[0;36mmodified_get_state\u001b[0;34m(self, kart_ix, use_ai)\u001b[0m\n\u001b[1;32m     26\u001b[0m terminated \u001b[38;5;241m=\u001b[39m kart\u001b[38;5;241m.\u001b[39mhas_finished_race\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Get the observation and update the world state\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkart_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ai\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m d_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, kart\u001b[38;5;241m.\u001b[39moverall_distance)\n\u001b[1;32m     32\u001b[0m f_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/envs.py:391\u001b[0m, in \u001b[0;36mBaseSTKRaceEnv.get_observation\u001b[0;34m(self, kart_ix, use_ai)\u001b[0m\n\u001b[1;32m    345\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mget_kart_action(kart_ix)\n\u001b[1;32m    346\u001b[0m     obs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([action\u001b[38;5;241m.\u001b[39macceleration], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m         }\n\u001b[1;32m    356\u001b[0m     }\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobs,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# World properties\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase\u001b[39m\u001b[38;5;124m\"\u001b[39m: Phase\u001b[38;5;241m.\u001b[39mfrom_stk(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mphase)\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux_ticks\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39maux_ticks], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# Kart properties\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpowerup\u001b[39m\u001b[38;5;124m\"\u001b[39m: kart\u001b[38;5;241m.\u001b[39mpowerup\u001b[38;5;241m.\u001b[39mnum,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattachment\u001b[39m\u001b[38;5;124m\"\u001b[39m: kart\u001b[38;5;241m.\u001b[39mattachment\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattachment_time_left\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    367\u001b[0m         [kart\u001b[38;5;241m.\u001b[39mattachment\u001b[38;5;241m.\u001b[39mtime_left], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    368\u001b[0m     ),\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_steer_angle\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39mmax_steer_angle], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39menergy], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskeed_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39mskeed_factor], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshield_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39mshield_time], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjumping\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kart\u001b[38;5;241m.\u001b[39mjumping \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# Kart physics (from the kart point view)\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance_down_track\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    376\u001b[0m         [kart\u001b[38;5;241m.\u001b[39mdistance_down_track], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    377\u001b[0m     ),\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvelocity\u001b[39m\u001b[38;5;124m\"\u001b[39m: kart\u001b[38;5;241m.\u001b[39mvelocity_lc,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfront\u001b[39m\u001b[38;5;124m\"\u001b[39m: kartview(kart\u001b[38;5;241m.\u001b[39mfront),\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# path center\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter_path_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([center_path_distance], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(x_orth),\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# Items (kart point of view)\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(items_position),\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(items_type),\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# Other karts (kart point of view)\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkarts_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(karts_position),\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Paths\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_distance, path_ix)),\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_width\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_width, path_ix)),\n\u001b[0;32m--> 391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_start\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkartview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterate_from\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_ix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_end\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    395\u001b[0m         kartview(x[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_nodes, path_ix)\n\u001b[1;32m    396\u001b[0m     ),\n\u001b[1;32m    397\u001b[0m }\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/envs.py:392\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    345\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mget_kart_action(kart_ix)\n\u001b[1;32m    346\u001b[0m     obs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([action\u001b[38;5;241m.\u001b[39macceleration], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m         }\n\u001b[1;32m    356\u001b[0m     }\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobs,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# World properties\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase\u001b[39m\u001b[38;5;124m\"\u001b[39m: Phase\u001b[38;5;241m.\u001b[39mfrom_stk(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mphase)\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux_ticks\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39maux_ticks], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# Kart properties\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpowerup\u001b[39m\u001b[38;5;124m\"\u001b[39m: kart\u001b[38;5;241m.\u001b[39mpowerup\u001b[38;5;241m.\u001b[39mnum,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattachment\u001b[39m\u001b[38;5;124m\"\u001b[39m: kart\u001b[38;5;241m.\u001b[39mattachment\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattachment_time_left\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    367\u001b[0m         [kart\u001b[38;5;241m.\u001b[39mattachment\u001b[38;5;241m.\u001b[39mtime_left], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    368\u001b[0m     ),\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_steer_angle\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39mmax_steer_angle], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39menergy], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskeed_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39mskeed_factor], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshield_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([kart\u001b[38;5;241m.\u001b[39mshield_time], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjumping\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kart\u001b[38;5;241m.\u001b[39mjumping \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# Kart physics (from the kart point view)\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance_down_track\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    376\u001b[0m         [kart\u001b[38;5;241m.\u001b[39mdistance_down_track], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    377\u001b[0m     ),\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvelocity\u001b[39m\u001b[38;5;124m\"\u001b[39m: kart\u001b[38;5;241m.\u001b[39mvelocity_lc,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfront\u001b[39m\u001b[38;5;124m\"\u001b[39m: kartview(kart\u001b[38;5;241m.\u001b[39mfront),\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# path center\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter_path_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([center_path_distance], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(x_orth),\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# Items (kart point of view)\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(items_position),\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(items_type),\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# Other karts (kart point of view)\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkarts_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(karts_position),\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Paths\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_distance, path_ix)),\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_width\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_width, path_ix)),\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_start\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 392\u001b[0m         \u001b[43mkartview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_nodes, path_ix)\n\u001b[1;32m    393\u001b[0m     ),\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_end\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    395\u001b[0m         kartview(x[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m iterate_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mpath_nodes, path_ix)\n\u001b[1;32m    396\u001b[0m     ),\n\u001b[1;32m    397\u001b[0m }\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/envs.py:277\u001b[0m, in \u001b[0;36mBaseSTKRaceEnv.get_observation.<locals>.kartview\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkartview\u001b[39m(x):\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a vector in the kart frame\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    X right, Y up, Z forwards\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/pystk2_gymnasium/utils.py:34\u001b[0m, in \u001b[0;36mrotate\u001b[0;34m(v, q)\u001b[0m\n\u001b[1;32m     31\u001b[0m x, y, z \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m     32\u001b[0m qw, qx, qy, qz \u001b[38;5;241m=\u001b[39m q\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "rewards = []\n",
    "for step in range(1000):\n",
    "    trajectories, last_state = collect_trajectories(env, last_state, model, n_steps=1000)\n",
    "    shuffled_trajectory = shufffle_trajectory(trajectories)\n",
    "    ppo_optimization(shuffled_trajectory, model, optimizer, epochs=4, batch_size=256)\n",
    "    \n",
    "    rewards.append(trajectories['rewards'].mean().item())\n",
    "    \n",
    "    \n",
    "    if step % 1 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(rewards)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
